# Crawlers That I've Created

Someone says it's painful to make web crawlers. I don't agree with that. Because many trivial and tedious problems about information process and collecting in people's life can be resolved by crawlers. Actually, the knowledge to programming crawlers helps me have a better life.

## Crawlers and Motivations

* `sspai` ([sspai.com](https://sspai.com), original name 少数派): One day I remembered that I had caught sight of a website in comment section that I urgently needed at that time. But I could't locate that comment. What's worst, comments of this website were fetched by XHR so I can't Google it. Therefore, I wrote a simple crawler with Python in 15 minutes. Finally I got what I want in 10 minutes of waiting.

* `toefl`: I was preparing my TOEFL exam. However, the test center in my city is in great demand so I could barely find a seat. I made this Tampermonkey script to refersh the page automatically. Once there is any available seat, it'll send me a notification via Chrome.

* `sdu`: This folder contains some scripts related to my University.
  * `card.js`: This script generates exported turnovers of my campus ID card into [Beancount][beancount] transactions.

[beancount]: https://github.com/beancount/beancount
